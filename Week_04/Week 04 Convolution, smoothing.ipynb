{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution & Smoothing\n",
    "\n",
    "In this notebook, we will review the operation of *convolution*, and how it is used to model the hemodynamic response function in fMRI. We will also show how convolution with a Gaussian kernel smooths data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Inline plots\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina'\n",
    "# A little config for image plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'equal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hemodynamic response function!\n",
    "The equation for the HRF given in Boynton et al 1996 is:\n",
    "\n",
    "# $h(t) = \\frac{(t/\\tau)^{n-1}e^{-t/\\tau}}{\\tau(n-1)!}$\n",
    "\n",
    "$t$ is time\n",
    "\n",
    "$\\tau$ is time constant, which governs the width of the function\n",
    "\n",
    "$n$ governs the delay in the response, and must be an integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Put this into python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill me in!\n",
    "from scipy.special import factorial\n",
    "\n",
    "def gammafun(t, tau, n):\n",
    "    \"\"\"Computes gamma function for values in t\"\"\"\n",
    "    num = ... # numerator of function above\n",
    "    denom = ... # denominator of function above\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE that this mathematical approximation of this HRF is NOT necessarily set in stone - there is no ground truth that says the HRF is and always should be a gamma function. This is a good-enough approximation (there are others out there that some say are slightly better). There is a large literature about estimating HRF parameters (as parameters of a gamma function and otherwise). One clear indicator of the kloodgy nature of the gamma function as an approximation of the HRF is that derivatives of the gamma function are often used along with it. \n",
    "\n",
    "The next cells show that you can create slightly different shapes of the HRF by fixing a gamma function and then adding a scaled version of the function's derivative back to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(32)\n",
    "g = gammafun(t, tau=1, n=6)\n",
    "# You may ask yourself, What does np.diff do on the next line? \n",
    "# Perhaps create a new cell and use the help: np.diff?\n",
    "dg = np.hstack([0, np.diff(g)]) \n",
    "ddg = np.hstack([0, np.diff(dg)])\n",
    "plt.plot(g, 'k', lw=2, label='Base HRF')\n",
    "plt.plot(dg, label='First derivative')\n",
    "plt.plot(ddg, label='Second derivative')\n",
    "plt.legend(frameon=False, fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g, 'k-', lw=2, label='Original HRF')\n",
    "plt.plot(g + 2 * dg, label='HRF + 2 * $\\delta$HRF')\n",
    "plt.plot(g - 2 * dg, label='HRF - 2 * $\\delta$HRF')\n",
    "plt.legend(frameon=False, fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolve the HRF with a stimulus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a canonical HRF\n",
    "t = np.arange(32) # 32 seconds @TR = 1 second\n",
    "hrf = gammafun(t, tau=1, n=6+1)\n",
    "\n",
    "plt.plot(t, hrf, '.-');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single discrete stimulus that appears at time 0\n",
    "stimulus = np.zeros(t.shape)\n",
    "stimulus[0] = 1\n",
    "\n",
    "plt.figure(1, figsize=(10, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(t, stimulus)\n",
    "\n",
    "# There is a better function that we can use to make this plot more explicit\n",
    "plt.subplot(122)\n",
    "plt.stem(t, stimulus, linefmt='k-', markerfmt='.', basefmt='k-', label='Stimulus');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be plotting stimulus / response pairs several times\n",
    "# Hence, here is a function that can plot these two together\n",
    "def stim_resp_plot(t, stimulus, response, yl=(-0.2, 1.2), label_stim='Stimulus', label_resp='BOLD response (HRF)'):\n",
    "    \"\"\"Plot stimulus and response.\"\"\"\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.stem(t, stimulus, linefmt='k-', markerfmt='.', basefmt='k-', label=label_stim)\n",
    "    plt.plot(t, response, 'r.-', label=label_resp)\n",
    "    plt.ylim(yl)\n",
    "    plt.xlim([-1,t.max()+1])\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Response (arbitrary units)')\n",
    "    _ = plt.legend()\n",
    "\n",
    "# Plot\n",
    "stim_resp_plot(t, stimulus, hrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200 # Total time points (TRs)\n",
    "t = np.arange(n,)\n",
    "\n",
    "# No stimulus\n",
    "stimuli = np.zeros((n))\n",
    "\n",
    "# We assume no response\n",
    "response = np.zeros((n))\n",
    "\n",
    "# Here we plot the function\n",
    "stim_resp_plot(t, stimuli, response, yl=(-0.2, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "A few cells above we plotted how the signal changes when we have a stimulus at time 0. \n",
    "\n",
    "Now, imagine we have a stimulus at time `i=10`. What do you expect will happen when we plot the stimulus and response?\n",
    "\n",
    "Hint: This stimulus will create an HRF that will be *added* to the signal from times i to times i + hrf_length (hrf_length is the length of our canonical HRF, which was 32 above).\n",
    "\n",
    "Attention: Make sure you modify the response by adding something to its values, and not only changing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "\n",
    "Now let's say that there were 3 event onsets, one at `i=10`, one at `i=70` and one at `i=150`, plot the resulting activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Now say that the stimuli are closer together than the length of the hemodynamic function: let's say they occur at times 10, 21, 25, 70, 71,74, 75, 80 and 150, what happens? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using python convolution function instead of rolling our own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use np.convolve to do effectively this same thing.\n",
    "rr = np.convolve(stimuli, hrf, mode='full')\n",
    "# rr is longer than stimuli by the length of the hrf, so we must crop it: \n",
    "rr = rr[:len(stimuli)]\n",
    "stim_resp_plot(t, stimuli, rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: using functions for convolution gets trickier, because you have to pay attention to edge effects, and how you want the convolution kernel to be centered on your data. For example, for the HRF, you want the full function to occur AFTER stimulus onset. However, if you want to smooth your data, you may want the peak of the convolution kernel to be centered on each point.\n",
    "\n",
    "**Blackboard chat...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General case of 1D smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some noise data\n",
    "n_timepoints = 100\n",
    "data = np.random.randn(n_timepoints,)\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a gaussian smoothing kernel\n",
    "n_c = 15\n",
    "n_ = np.floor(n_c/2).astype(np.int)\n",
    "# Range over which we will compute Gaussian\n",
    "x = np.linspace(-3, 3, n_c)\n",
    "# Simple Gaussian equation\n",
    "g = np.e**(-x**2)\n",
    "# To not change the amplitude of the response, the SUM of a smoothing kernel should equal 1!\n",
    "g /= np.sum(g)\n",
    "print(np.sum(g))\n",
    "plt.plot(x,g, '.-')\n",
    "plt.grid(axis='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help!\n",
    "np.convolve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple case\n",
    "s = np.zeros((100,))\n",
    "s[5] = 1\n",
    "s_c = np.convolve(s, g, mode='same')\n",
    "s_c2 = np.convolve(s, g, mode='full')\n",
    "s_c2 = s_c2[n_:-n_]\n",
    "print(np.allclose(s_c2, s_c))\n",
    "print(s_c.shape)\n",
    "plt.plot(s);\n",
    "plt.plot(s_c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c = np.convolve(data, g, mode='full')\n",
    "n_ = np.floor(n_c/2).astype(np.int)\n",
    "data_c = data_c[n_:-n_]\n",
    "plt.plot(data, label='original')\n",
    "plt.plot(data_c, label='smoothed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Create a filter to take a block average rather than a Gaussian kernel. Test it on some simple data (e.g., convolve it with `s` created above), then convolve it with the data above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution w/ Gaussian kernel (smoothing) in 2D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [101, 101]\n",
    "data2d = np.random.randn(*dims)\n",
    "plt.imshow(data2d);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Create a 2D Gaussian kernel! The equation for a 2D Gaussian is:\n",
    "\n",
    "# $g = e^{-\\frac{(x-\\mu_x)^2}{2\\sigma^2_x} + \\frac{(y-\\mu_y)^2}{2\\sigma^2_y}}$\n",
    "\n",
    "$\\sigma_x$ is the standard deviation of the Gaussian in the x dimension\n",
    "\n",
    "$\\sigma_y$ is the standard deviation of the Gaussian in the y dimension\n",
    "\n",
    "Critical to this endeavor is defining the X and Y over which the function will be evaluated. To do that, you need a *grid* of values (arrays of x and y values that vary linearly in the x and y dimensions). To create such a grid, use `np.meshgrid`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Hint / help cell)\n",
    "kernel_size = 7 # pixels\n",
    "xyrange = np.linspace(-3, 3, kernel_size)\n",
    "x, y = np.meshgrid(xyrange, xyrange)\n",
    "print('x:')\n",
    "print(x)\n",
    "print('y:')\n",
    "print(y)\n",
    "# This x and y should go into the computation of your 2D Gaussian!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill me in!\n",
    "g = np.exp(x+y) #...\n",
    "\n",
    "# (better still, make this a function that takes inputs mu_x, mu_y, sigma_x, sigma_y...)\n",
    "def make_gauss(x, y, mu_x, mu_y, sigma_x, sigma_y):\n",
    "    g = 0 #...\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To smooth the image, convolve this kernel with the image, using a convolve2d function! The principle is approximately the same as with the 1D case, but now the filter acts over two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not in the same library, because python.\n",
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2d_c = convolve2d(data2d, g2d, mode='full')\n",
    "n_ = np.floor(n_c/2).astype(np.int)\n",
    "data2d_c = data2d_c[n_:-n_, n_:-n_]\n",
    "print(data2d_c.shape)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "axs[0].imshow(data2d);\n",
    "axs[1].imshow(data2d_c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = data.coins()\n",
    "image_c = convolve2d(image, g2d, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "ax1.imshow(image, cmap='gray')\n",
    "ax2.imshow(image_c, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "Make it blurrier! How would you blur out more of the coins? DO IT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing can reveal real signal hidden in noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2d_noisy = np.random.randn(*dims)\n",
    "data2d_noisy[10:30,10:30] += 0.6\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "axs[0].imshow(data2d_noisy)\n",
    "data2d_noisy_c = convolve2d(data2d_noisy, g2d, mode='same')\n",
    "axs[1].imshow(data2d_noisy_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... But also can obscure potentially real variation at a scale smaller than the smoothing kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Create a design matrix as we did last week, and convolve each column of X with the boynton HRF! Use THAT X to generate data (plus some noise) (This is how the fMRI signal is modeled in the Boynton paper!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ...\n",
    "B = ...\n",
    "# Convolve X with the HRF function\n",
    "Xc = np.convolve()\n",
    "E = ...\n",
    "Y = X.dot(B) + E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "Estimate $\\beta$ from your simulated data using the regression equation from last week. \n",
    "\n",
    "Play with the noise level until your estimated $\\beta$ weights become inaccurate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced exercise\n",
    "\n",
    "See if you can create a design matrix that will NOT allow you to accurately estimate B weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
